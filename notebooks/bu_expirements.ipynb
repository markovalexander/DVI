{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as  np\n",
    "import math\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from bayes_util import standard_gaussian, gaussian_cdf, softrelu, g, delta, heavy_g, make_random_covariance_matrix\n",
    "\n",
    "EPS = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py:1645: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "sess= tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_gaussian_torch(x):\n",
    "    pi = torch.FloatTensor([math.pi]).to(x.device)\n",
    "    const = 1 / torch.sqrt(2 * pi)\n",
    "    return const * torch.exp(-1 / 2 * x * x)\n",
    "\n",
    "def gaussian_cdf_torch(x):\n",
    "    const = 1 / np.sqrt(2)\n",
    "    return 0.5 * (1 + torch.erf(x * const))\n",
    "\n",
    "def softrelu_torch(x):\n",
    "    return standard_gaussian_torch(x) + x * gaussian_cdf_torch(x)\n",
    "\n",
    "def heaviside_q(rho, mu1, mu2):\n",
    "    \"\"\"\n",
    "        Computes exp( -Q(rho, mu1, mu2)) for Heaviside activation function.\n",
    "        \n",
    "    \"\"\"\n",
    "    rho_hat = torch.sqrt(1 - rho * rho)\n",
    "    arcsin = torch.asin(rho)\n",
    "    \n",
    "    rho_s = torch.abs(rho) + EPS\n",
    "    arcsin_s = torch.abs(torch.asin(rho)) + EPS\n",
    "        \n",
    "    A = arcsin / (2 * math.pi)\n",
    "    coef = rho_s / (2 * arcsin_s * rho_hat)\n",
    "    coefs_prod = (rho * rho) / (arcsin_s * rho_hat * (1 + rho_hat))\n",
    "    return A * torch.exp(-(mu1*mu1 + mu2*mu2) * coef + mu1 * mu2 * coefs_prod)\n",
    "\n",
    "\n",
    "def relu_q(rho, mu1, mu2):\n",
    "    \"\"\"\n",
    "        Computes exp( -Q(rho, mu1,  mu2)) for ReLU activation function.\n",
    "    \"\"\"\n",
    "    rho_hat_plus_one = torch.sqrt(1 - rho * rho) + 1\n",
    "    g_r = torch.asin(rho) - rho / rho_hat_plus_one   # why minus?\n",
    "    \n",
    "    rho_s = torch.abs(rho) + EPS\n",
    "    g_r_s = torch.abs(g_r) + EPS\n",
    "    A = g_r / (2 * math.pi)\n",
    "    \n",
    "    coef_sum =  rho_s / (2 * g_r_s * rho_hat_plus_one)\n",
    "    coef_prod = (torch.asin(rho) - rho) / (rho_s * g_r_s)\n",
    "    return A * torch.exp(- (mu1 * mu1 + mu2 * mu2) * coef_sum + coef_prod * mu1 * mu2)\n",
    "\n",
    "\n",
    "def delta_torch(rho, mu1, mu2):\n",
    "    return gaussian_cdf_torch(mu1) * gaussian_cdf_torch(mu2) + relu_q(rho, mu1, mu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_answer(function, value, mu1 = None, mu2 = None):\n",
    "    value = np.array(value)\n",
    "    if mu1 is  None:\n",
    "        x  = tf.placeholder(tf.float32, shape = value.shape)\n",
    "        f = function(x)\n",
    "        return sess.run(f, feed_dict={x: value})\n",
    "    else:\n",
    "        mu1 = np.array(mu1)\n",
    "        mu2 = np.array(mu2)\n",
    "        \n",
    "        rho = tf.placeholder(tf.float32, shape = value.shape)\n",
    "        mu_1 = tf.placeholder(tf.float32, shape = mu1.shape)\n",
    "        mu_2 = tf.placeholder(tf.float32, shape = mu2.shape)\n",
    "        \n",
    "        f = function(rho, mu_1, mu_2)\n",
    "        return sess.run(f, feed_dict={rho: value, mu_1: mu1, mu_2: mu2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = torch.FloatTensor([1, 0.01, -1])\n",
    "mu1 = torch.FloatTensor([-1, 0, -1])\n",
    "mu2 = torch.FloatTensor([2, -0.5, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1552, 0.1550, 0.0194])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_torch(rho, mu1, mu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15519984, 0.15497105, 0.0193752 ], dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tf_answer(delta, [1, 0.01,  -1], [-1, 0, -1], [2, -0.5, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
